<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Discoveries Online</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="container d-flex">

      <div class="container d-flex">
      <div class="logo mr-auto">
        <!-- <h1 class="text-light"><a href="index.html">Discoveries Online<span>.</span></a></h1> -->
        <a href="index.html">
          <picture >
            <source media="(max-width: 768px)"
                    srcset="assets/img/discoveries_logo_alt_767px.png">
            <source media="(min-width: 769px)"
                    srcset="assets/img/discoveries_logo.png">
            <img id="header-logo" src="assets/img/discoveries_logo.png" alt="" class="img-fluid">
          </picture>
          </a>
      </div>
    </div>

      <nav class="nav-menu d-none d-lg-block">
        <ul>
          <li class="drop-down"><a href="">Guides for remote research</a>
            <ul>
              <li><a href="pre-registration.html">Pre-registration</a></li>
              <li><a href="irb.html">IRB language</a></li>
              <li class="drop-down"><a href="design.html">Designing child-friendly remote studies</a>
                <ul>
                  <li><a href="design.html#adapt">Adapting studies for remote research</a></li>
                  <li><a href="design.html#prepare">Preparing stimuli</a></li>
                  <li><a href="design.html#create">Creating animations</a></li>
                  <li><a href="design.html#qualtrics">Setting up studies on Qualtrics</a></li>
                </ul>
              </li>
              <li><a href="hostmystudy.html">Hosting studies online</a></li>
              <li><a href="datavyu.html">Processing webcam data</a></li>
              <li><a href="parents.html">The role of parents</a></li>
              <li><a href="recruitment.html">Sample recruitment materials</a></li>
            </ul>
          </li>
          <li class="get-started"><a href="hostmystudy.html">Host my study</a></li>
        </ul>
      </nav>
      <!-- .nav-menu -->

    </div>
  </header><!-- End Header -->

  <main id="main">


    <!-- ======= Features Section ======= -->
    <section id="features" class="features section-bg">
      <div class="container">

        <div class="section-title">
          <h2 data-aos="fade-in">Making the most of webcam videos using Datavyu and Databrary</h2>
          <p data-aos="fade-in">
              Videos are an essential part of the conducting unmoderated remote research because they assure that data collected via behavioral measures is usable (how else would we know that a child actually did the study!)&mdash;but they also allow us to collect a richer dataset that can be used to answer novel research questions that cannot be captured in traditional psychological measures. 
          </p>
        </div>

        <div class="row content" data-aos="fade-in">
          <div class="pt-4">
            <h3>How our lab uses Datavyu</h3>
            <p>
                Once parents have uploaded their video recordings for each participant, the videos go through a Quality Assurance procedure (QA) as the first stage of data processing to determine whether the data are valid or not (see 
                <a href="hostmystudy.html#data-validation">here for details of how we do this</a>). But even for valid study sessions, some additional processing is needed to make sure that we end up with reliable, high-quality data. For example, given that the studies are conducted with no direct contact with an experimenter, it’s important to ensure that children’s responses are not influenced by interference from other people, so we code videos of study sessions for interference. This coding involves having a trained researcher watch the video and mark any portions of the study in which a parent or other person interfered with the child’s response using the video coding platform Datavyu, a free open-source video coding system (Lingeman, Freeman, & Adolph, 2014; Datavyu.org). Coding in Datavyu allows researchers to extract data from video recordings of study sessions in a concise and organized way. This includes both coding for potential interference, as well as coding for interesting aspects of children’s interactions with people around them during testing (see 
                <a href="parents.html">here for more info about the role of parents</a> and why it’s important to code for it).<br><br>

                What proportion of videos to code varies by study, depending on both the topic and whether or not aspects of the child’s interaction with parents are included as dependent variables in the study design. For some studies, in which the likelihood of parental interference is high or is of interest, researchers might choose to code 100% of videos for interference. For other studies, in which the likelihood of interference is low and parent-child interactions are not part of the planned study design, researchers might choose to code a randomly selected subset of videos in order to assess the interference rate (see <a href="pre-registration.html">here for more details</a>). Our previous unmoderated remote research with these methods has identified extremely low rates of parent or sibling interference (less than 1% of trials), and excluding such trials had no consequence for the overall pattern of findings (Leshin, Leslie, & Rhodes, 2020). So for some studies, we randomly select 20% of videos to be coded by a trained researcher in order to estimate the interference rate. If the interference rate in the subset of coded videos is less than 3%, then we conclude that it does not affect the study results (see this study for more information about interference rates found in our previous studies and detailed analysis). If the estimated rate of interference is more than 3%, however, then we instead code every video trial-by-trial for instances of interference and exclude any trials in which there was interference such that there is a question of whether the answer reflects the child’s response. If more than 25% of trials are excluded due to interference, then we do not include the participant’s data in analyses. We specify these coding plans in each study’s pre-registration (see <a href="pre-registration.html">here for an example</a>).<br><br>

                In order to be able to exclude trials for interference, the study has to be set up in a way that allows accurate information about what participants are seeing at any given time during the video. One way of setting this up is by embedding data in the study about when each trial begins and ends (see 
                <a href="design.html#embed-time">our guide</a> for setting this up). Once you have run your study, and you have webcam videos of study sessions and a Qualtrics file with the onsets and offsets of each trial, you can import the timing data into Datavyu to track what participants are seeing during each part of their video. Here's a <a href="assets/resources/datavyu/import_qualtrics.rb" target="_blank">sample Ruby script</a> that we use to import our Qualtrics data into Datavyu.<br><br>

                In addition to using Datavyu to code for interference, we can also use the platform to code for variables of interest, like conversations between parents and children as well as behavioral aspects of children’s interactions with the other people in their home environments (see <a href="https://osf.io/htn7z/" target="_blank">this study</a> as an example of using Datavyu to code for parent and child speech and behavior). 
            </p>
          </div>
    
              <div class="pt-4">
            <h3>Sharing videos with other researchers via Databrary</h3>
            <p>
             Webcam video is rich data, so each video offers a wealth of potential developmental data for researchers beyond the scope of the specific study’s questions. In order to share this rich data with the research community, we ask at the end of every study session for parents’ permission to share the video data with authorized researchers on <a href="https://www.databrary.org" target="_blank">Databrary</a>. Sharing videos on Databrary also helps with reproducibility and reliability (see here for more info). <br><br>

            Here is a screenshot of how that looks:
            </p>

            <div class="center_box">
                <img class="img_center" style="width: 60%;" src="assets/img/datavyu/databrary_consent.png">
            </div>
            </div>
          </div>
        </div>
    </section>
  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container footer-bottom clearfix">
      <div class="copyright">
        <strong><span>Discoveries Online</span></strong> documentation is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
      </div>
      <div class="credits" style="text-align: left;">
        <br>
          This material was supported by the Eunice Kennedy Shriver National Institute of Child Health & Human Development of the National Institutes of Health under Award Number R01HD087672 to Rhodes and F31HD093431 to Foster-Hanson. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. This project was also supported by National Science Foundation award BCS-1729540 and a McDonnell Scholars Award to Rhodes, the Beyond Conflict Innovation Lab, funding from Princeton University and New York University, and an NSF Graduate Research Fellowship to Moty
        <br><br>
        To cite this website or our paper, please use:<br>
            Rhodes, M., Rizzo, M. T., Foster-Hanson, E., Moty, K., Leshin, R. A., Wang, M., Benitez, J., & Ocampo, J. D. (2020). 
            <span class="font-italic">Advancing developmental science via unmoderated remote research with children</span>.
            <a href="https://doi.org/10.1080/15248372.2020.1797751" target="_blank">Journal of Cognition and Development</a>, 21(4): 477-493.
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
